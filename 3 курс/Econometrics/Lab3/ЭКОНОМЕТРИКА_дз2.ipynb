{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ЭКОНОМЕТРИКА_дз2.ipynb\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.3 32-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "f36bb2415103839c44be3616e885f7d6aee90348d429d9698a9148e0dea357be"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4-HzMUPYW7P"
      },
      "source": [
        "# **ЭКОНОМЕТРИКА**\n",
        "## Домашняя работа №2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiN-Ow4dYffH"
      },
      "source": [
        "## *Множественная регрессия*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Wno7VPgaSx1"
      },
      "source": [
        "#### **Задание.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULITFVwIafjl"
      },
      "source": [
        "Постройте линейную модель множественной регрессии.\n",
        "\n",
        "Оцените ее качество. Сделайте тесты на значимость модели в целом и отдельно на значимость ее параметров.\n",
        "\n",
        "Постройте парную модель регрессии, для этого выберите фактор, который оказывает наибольшее влияние на эндогенную переменную.\n",
        "\n",
        "Сравните характеристики качества двух моделей. Выберите лучшую.\n",
        "\n",
        "Для выбранной модели рассчитайте бетта и дельта коэффициенты, коэффициенты эластичности.\n",
        "\n",
        "Проинтерпретируйте полученные результаты."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCSBPeRQ3PeF"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elqJuPbZ3_0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "outputId": "ebfcbd62-4824-41d1-a090-434f9238257d"
      },
      "source": [
        "data = pd.read_csv('https://raw.githubusercontent.com/Cat-in-box/FA/main/3%20%D0%BA%D1%83%D1%80%D1%81/Econometrics/Lab3/data.csv', delimiter=';', header=0, names=['№','y','x1','x2','x3', 'x4']).drop('№', axis=1)\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12345.0</td>\n",
              "      <td>2769</td>\n",
              "      <td>29.67</td>\n",
              "      <td>94.2</td>\n",
              "      <td>9.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12091.9</td>\n",
              "      <td>3065</td>\n",
              "      <td>28.94</td>\n",
              "      <td>101.1</td>\n",
              "      <td>9.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12339.7</td>\n",
              "      <td>3899</td>\n",
              "      <td>28.43</td>\n",
              "      <td>111.6</td>\n",
              "      <td>9.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12450.6</td>\n",
              "      <td>3790</td>\n",
              "      <td>27.50</td>\n",
              "      <td>119.7</td>\n",
              "      <td>9.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12832.1</td>\n",
              "      <td>3963</td>\n",
              "      <td>28.07</td>\n",
              "      <td>112.0</td>\n",
              "      <td>9.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>12892.1</td>\n",
              "      <td>4224</td>\n",
              "      <td>28.08</td>\n",
              "      <td>112.0</td>\n",
              "      <td>9.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>13224.5</td>\n",
              "      <td>4645</td>\n",
              "      <td>27.68</td>\n",
              "      <td>115.3</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>13449.9</td>\n",
              "      <td>4914</td>\n",
              "      <td>28.86</td>\n",
              "      <td>109.6</td>\n",
              "      <td>8.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>13476.8</td>\n",
              "      <td>4830</td>\n",
              "      <td>31.88</td>\n",
              "      <td>112.6</td>\n",
              "      <td>7.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>13588.9</td>\n",
              "      <td>4815</td>\n",
              "      <td>29.90</td>\n",
              "      <td>108.7</td>\n",
              "      <td>7.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>13600.4</td>\n",
              "      <td>4401</td>\n",
              "      <td>31.32</td>\n",
              "      <td>110.9</td>\n",
              "      <td>6.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>13768.5</td>\n",
              "      <td>5189</td>\n",
              "      <td>32.20</td>\n",
              "      <td>108.0</td>\n",
              "      <td>6.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>14796.6</td>\n",
              "      <td>3434</td>\n",
              "      <td>30.36</td>\n",
              "      <td>109.8</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14424.2</td>\n",
              "      <td>5195</td>\n",
              "      <td>28.95</td>\n",
              "      <td>119.2</td>\n",
              "      <td>3.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14607.3</td>\n",
              "      <td>5401</td>\n",
              "      <td>29.33</td>\n",
              "      <td>123.3</td>\n",
              "      <td>3.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>14688.0</td>\n",
              "      <td>4239</td>\n",
              "      <td>29.36</td>\n",
              "      <td>117.8</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>15057.3</td>\n",
              "      <td>4558</td>\n",
              "      <td>32.45</td>\n",
              "      <td>109.2</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>15161.0</td>\n",
              "      <td>4675</td>\n",
              "      <td>32.82</td>\n",
              "      <td>93.5</td>\n",
              "      <td>4.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>15534.6</td>\n",
              "      <td>6558</td>\n",
              "      <td>32.19</td>\n",
              "      <td>102.7</td>\n",
              "      <td>5.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>15544.5</td>\n",
              "      <td>6253</td>\n",
              "      <td>32.92</td>\n",
              "      <td>113.5</td>\n",
              "      <td>5.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>15644.4</td>\n",
              "      <td>5410</td>\n",
              "      <td>30.92</td>\n",
              "      <td>112.0</td>\n",
              "      <td>6.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>15717.8</td>\n",
              "      <td>5023</td>\n",
              "      <td>31.53</td>\n",
              "      <td>110.8</td>\n",
              "      <td>6.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          y    x1     x2     x3   x4\n",
              "0   12345.0  2769  29.67   94.2  9.6\n",
              "1   12091.9  3065  28.94  101.1  9.5\n",
              "2   12339.7  3899  28.43  111.6  9.5\n",
              "3   12450.6  3790  27.50  119.7  9.6\n",
              "4   12832.1  3963  28.07  112.0  9.6\n",
              "5   12892.1  4224  28.08  112.0  9.4\n",
              "6   13224.5  4645  27.68  115.3  9.0\n",
              "7   13449.9  4914  28.86  109.6  8.2\n",
              "8   13476.8  4830  31.88  112.6  7.2\n",
              "9   13588.9  4815  29.90  108.7  7.2\n",
              "10  13600.4  4401  31.32  110.9  6.8\n",
              "11  13768.5  5189  32.20  108.0  6.1\n",
              "12  14796.6  3434  30.36  109.8  4.2\n",
              "13  14424.2  5195  28.95  119.2  3.7\n",
              "14  14607.3  5401  29.33  123.3  3.7\n",
              "15  14688.0  4239  29.36  117.8  3.6\n",
              "16  15057.3  4558  32.45  109.2  3.6\n",
              "17  15161.0  4675  32.82   93.5  4.3\n",
              "18  15534.6  6558  32.19  102.7  5.6\n",
              "19  15544.5  6253  32.92  113.5  5.9\n",
              "20  15644.4  5410  30.92  112.0  6.6\n",
              "21  15717.8  5023  31.53  110.8  6.5"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_0z8cFSVZfO"
      },
      "source": [
        "Y = data['y']\n",
        "X = data.drop('y', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtA4DboPXET6"
      },
      "source": [
        "yi = α + β1 x1i + β2 x2i + β3 x3i + β4 x4i + εi\n",
        "\n",
        "ŷi = a + b1 x1i + b2 xi + b3 x3i + b4 x4i"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrjgjzPFVZ0t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5abc320f-a2b9-42ac-b51e-434ff0975837"
      },
      "source": [
        "Model = LinearRegression()\n",
        "Model.fit(X, Y)\n",
        "a = Model.intercept_\n",
        "b1, b2, b3, b4 = Model.coef_\n",
        "print(f'ŷi = {a} + {b1} x1i + {b2} xi + {b3} x3i + {b4} x4i'.format(a, b1, b2, b3, b4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ŷi = 10399.933345978963 + 0.48377730418812775 x1i + 130.31505019722653 xi + -6.467802630559845 x3i + -276.37273409459976 x4i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8yyaWs2bH2_"
      },
      "source": [
        "**Оценка качества:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmVJrTbC6Ski",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc7c785a-37cd-4a6c-bf5e-4aa4039ae2f5"
      },
      "source": [
        "Se = np.sqrt(sum((Model.predict(X) - Y)**2)/(len(Y) - 4 - 1))\n",
        "R_2 = Model.score(X, Y)\n",
        "F = (R_2/(1 - R_2))*((len(Y) - 4 - 1)/4)\n",
        "A = sum((abs(Y - Model.predict(X)))/Y)/len(Y)*100\n",
        "\n",
        "print(f'Se = {Se}\\nR_2 = {R_2}\\nF = {F}\\nA = Eотн = {A}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se = 586.3207563508015\n",
            "R_2 = 0.806356957603642\n",
            "F = 17.697599807386283\n",
            "A = Eотн = 2.5974298012727917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylc8H0QGg04w"
      },
      "source": [
        "Так как средняя ошибка аппроксимации отличная от"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bH3mrH1hQOp"
      },
      "source": [
        "**Оценка модели на значимость в целом:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKPKGZeogz59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04ba75f4-dcff-4003-a4f0-c0b3f8473bef"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "est = sm.OLS(Y, sm.add_constant(X))\n",
        "est2 = est.fit()\n",
        "print(est2.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.806\n",
            "Model:                            OLS   Adj. R-squared:                  0.761\n",
            "Method:                 Least Squares   F-statistic:                     17.70\n",
            "Date:                Sat, 02 Oct 2021   Prob (F-statistic):           6.83e-06\n",
            "Time:                        11:10:17   Log-Likelihood:                -168.61\n",
            "No. Observations:                  22   AIC:                             347.2\n",
            "Df Residuals:                      17   BIC:                             352.7\n",
            "Df Model:                           4                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const        1.04e+04   6169.698      1.686      0.110   -2616.991    2.34e+04\n",
            "x1             0.4838      0.196      2.463      0.025       0.069       0.898\n",
            "x2           130.3151    132.126      0.986      0.338    -148.446     409.076\n",
            "x3            -6.4678     25.698     -0.252      0.804     -60.686      47.750\n",
            "x4          -276.3727     78.946     -3.501      0.003    -442.935    -109.810\n",
            "==============================================================================\n",
            "Omnibus:                        5.043   Durbin-Watson:                   1.083\n",
            "Prob(Omnibus):                  0.080   Jarque-Bera (JB):                2.978\n",
            "Skew:                           0.808   Prob(JB):                        0.226\n",
            "Kurtosis:                       3.797   Cond. No.                     2.32e+05\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 2.32e+05. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFuu3qGCdNoB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}